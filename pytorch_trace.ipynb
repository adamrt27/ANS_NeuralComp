{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN class\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function to compute global min and max\n",
    "def get_global_min_max(tensors):\n",
    "    min_val = float('inf')\n",
    "    max_val = float('-inf')\n",
    "    for tensor in tensors:\n",
    "        min_val = min(min_val, tensor.min().item())\n",
    "        max_val = max(max_val, tensor.max().item())\n",
    "    return min_val, max_val\n",
    "\n",
    "# Function to quantize tensors using common bins\n",
    "def quantize_tensor_to_int(tensor, bin_edges):\n",
    "    \"\"\"\n",
    "    Quantize the tensor into integer bins.\n",
    "    \n",
    "    Args:\n",
    "    tensor (torch.Tensor): The tensor to be quantized.\n",
    "    bin_edges (np.ndarray): The edges of the bins.\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: The quantized tensor represented by bin indices.\n",
    "    \"\"\"\n",
    "    # Flatten the tensor to a 1D array\n",
    "    flattened_tensor = tensor.flatten()\n",
    "    \n",
    "    # Digitize the tensor into bins\n",
    "    quantized_indices = np.digitize(flattened_tensor.numpy(), bin_edges) - 1\n",
    "    quantized_indices = np.clip(quantized_indices, 0, len(bin_edges) - 2)  # Ensure indices are within valid range\n",
    "    \n",
    "    # Reshape the quantized tensor to the original shape\n",
    "    quantized_tensor = torch.tensor(quantized_indices, dtype=torch.int32).reshape(tensor.shape)\n",
    "    \n",
    "    return quantized_tensor\n",
    "\n",
    "# Function to capture intermediate outputs and prepare for quantization\n",
    "def get_intermediate_outputs(model, input_data):\n",
    "    intermediate_outputs = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        intermediate_outputs.append(input[0])\n",
    "        intermediate_outputs.append(output)\n",
    "\n",
    "    hooks = []\n",
    "    for layer in model.children():\n",
    "        hook = layer.register_forward_hook(hook_fn)\n",
    "        hooks.append(hook)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        model(input_data)\n",
    "\n",
    "    # Remove hooks\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    return intermediate_outputs\n",
    "\n",
    "# Quantize and save all tensors\n",
    "def save_tensor_as_list(tensor, filename):\n",
    "    tensor_list = tensor.cpu().numpy().tolist()  # Convert tensor to list\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(tensor_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors have been saved as JSON files.\n",
      "Intermediate Output 0: [[9, 7], [6, 6], [4, 15]]\n",
      "Intermediate Output 1: [[3, 3, 3, 4], [4, 3, 4, 4], [8, 3, 0, 1]]\n",
      "Intermediate Output 2: [[4, 4, 4, 4], [4, 4, 4, 4], [8, 4, 4, 4]]\n",
      "Intermediate Output 3: [[5], [5], [5]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ANN()\n",
    "\n",
    "# Define an input tensor with appropriate shape\n",
    "input_tensor = torch.randint(0, 10, (3, 2), dtype=torch.float)\n",
    "\n",
    "# Capture intermediate outputs\n",
    "intermediate_outputs = get_intermediate_outputs(model, input_tensor)\n",
    "\n",
    "# Include input_tensor in the tensors to be quantized\n",
    "all_tensors = [input_tensor] + intermediate_outputs\n",
    "\n",
    "# Compute global min and max\n",
    "global_min, global_max = get_global_min_max(all_tensors)\n",
    "\n",
    "# Number of bins for quantization\n",
    "num_bins = 16\n",
    "\n",
    "# Create bin edges\n",
    "bin_edges = np.linspace(global_min, global_max, num_bins + 1)\n",
    "\n",
    "# quantize tensors\n",
    "quantized_input_tensor = quantize_tensor_to_int(input_tensor, bin_edges)\n",
    "save_tensor_as_list(quantized_input_tensor, 'input_tensor.json')\n",
    "\n",
    "for i, tensor in enumerate(intermediate_outputs):\n",
    "    quantized_tensor = quantize_tensor_to_int(tensor, bin_edges)\n",
    "    save_tensor_as_list(quantized_tensor, f\"intermediate_output_{i}.json\")\n",
    "\n",
    "print(\"Tensors have been saved as JSON files.\")\n",
    "\n",
    "# Print verification\n",
    "for i, tensor in enumerate(intermediate_outputs):\n",
    "    quantized_tensor = quantize_tensor_to_int(tensor, bin_edges)\n",
    "    tensor_list = quantized_tensor.cpu().numpy().tolist()\n",
    "    \n",
    "    print(f\"Intermediate Output {i}: {tensor_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tANS_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
